{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from units import *\n",
    "from profiles import Profiles\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A toy simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoSim:\n",
    "    def __init__(self, theta_x_lims=[-1.6, 1.6], theta_y_lims=[-0.9, 0.9]):\n",
    "        \"\"\"\n",
    "        Class to create animations of astrometric weak lensing. For demo and not science!\n",
    "        :param theta_x_lims: x-axis coordinate limits [x_min, x_max] in arcsecs\n",
    "        :param theta_y_lims: y-axis coordinate limits [y_min, y_max] in arcsecs\n",
    "        \"\"\"\n",
    "\n",
    "        self.theta_x_lims = theta_x_lims\n",
    "        self.theta_y_lims = theta_y_lims\n",
    "\n",
    "        # Area of sky region\n",
    "        self.roi_area = (self.theta_x_lims[1] - self.theta_x_lims[0]) * \\\n",
    "                        (self.theta_y_lims[1] - self.theta_y_lims[0])\n",
    "\n",
    "    def animation(self, pos_l, M_l, R_l, v_l, D_l,\n",
    "                  n_sources_fix=True,\n",
    "                  # Source properties\n",
    "                  std_mu_s=1e-6,\n",
    "                  n_dens=20, source_pos=\"random\"\n",
    "                  ):\n",
    "        \"\"\"\n",
    "        :param pos_l: tuple of lens positions, format [[x_1, y_1], [x_2, y_2]...]\n",
    "        :param M_l: tuple of lens masses\n",
    "        :param R_l: tuple of lens sizes (Gaussian lens)\n",
    "        :param v_l: tuple of lens velocities\n",
    "        :param D_l: tuple of distances of lenses\n",
    "        :param n_dens: density of sources (per arcsecs^2); default 20\n",
    "        :param source_pos: must be one of [\"uniform\", \"random\"]; default \"random\"\n",
    "        \"\"\"\n",
    "\n",
    "        # Get total number of sources in sky region\n",
    "        \n",
    "        if n_sources_fix:\n",
    "            self.n_total = np.floor(n_dens * self.roi_area).astype(np.int32)\n",
    "        else:\n",
    "            self.n_total = np.random.poisson(n_dens * self.roi_area)\n",
    "        \n",
    "        # Source velocities\n",
    "        self.mu_s_intrinsic = np.random.normal(loc=0, scale=std_mu_s, size=(ds.n_total, 2))\n",
    "        \n",
    "        # Set source positions\n",
    "\n",
    "        # Random positions + custom if specified\n",
    "        if source_pos == \"random\":\n",
    "\n",
    "            # Initial source property array\n",
    "            self.sources = np.zeros(self.n_total, dtype=[(\"theta_x\", float, 1),\n",
    "                                                         (\"theta_y\", float, 1),\n",
    "                                                         (\"theta_x_0\", float, 1),\n",
    "                                                         (\"theta_y_0\", float, 1),\n",
    "                                                         (\"mu\", float, 1)])\n",
    "\n",
    "            self.sources[\"theta_x_0\"] = np.array(\n",
    "                list(np.random.uniform(*self.theta_x_lims, self.n_total)))\n",
    "            self.sources[\"theta_y_0\"] = np.array(\n",
    "                list(np.random.uniform(*self.theta_x_lims, self.n_total)))\n",
    "\n",
    "        # Uniform grid of sources\n",
    "        elif source_pos == \"uniform\":\n",
    "            xy_ratio = (self.theta_y_lims[1] - self.theta_y_lims[0]) / \\\n",
    "                (self.theta_x_lims[1] - self.theta_x_lims[0])\n",
    "            x_pos = np.linspace(self.theta_x_lims[0], self.theta_x_lims[1], np.round(\n",
    "                np.sqrt(self.n_total / xy_ratio)))\n",
    "            y_pos = np.linspace(self.theta_y_lims[0], self.theta_y_lims[1], np.round(\n",
    "                np.sqrt(self.n_total * xy_ratio)))\n",
    "\n",
    "            self.n_total = len(np.meshgrid(x_pos, y_pos)[0].flatten())\n",
    "\n",
    "            # Initialize source property array\n",
    "            self.sources = np.zeros(self.n_total, dtype=[(\"theta_x\", float, 1),\n",
    "                                                         (\"theta_y\", float, 1),\n",
    "                                                         (\"theta_x_0\", float, 1),\n",
    "                                                         (\"theta_y_0\", float, 1)])\n",
    "\n",
    "            self.sources[\"theta_x_0\"] = np.meshgrid(x_pos, y_pos)[0].flatten()\n",
    "            self.sources[\"theta_y_0\"] = np.meshgrid(x_pos, y_pos)[1].flatten()\n",
    "\n",
    "        assert len(pos_l) == len(v_l) == len(M_l) == len(R_l) == len(D_l), \\\n",
    "            \"Lens property arrays must be the same size!\"\n",
    "\n",
    "        # Infer number of lenses\n",
    "        self.n_lens = len(pos_l)\n",
    "\n",
    "        # Initialize lens property array\n",
    "        self.lenses = np.zeros(self.n_lens, dtype=[(\"theta_x\", float, 1),\n",
    "                                                   (\"theta_y\", float, 1),\n",
    "                                                   (\"M_0\", float, 1),\n",
    "                                                   (\"R_0\", float, 1),\n",
    "                                                   (\"D\", float, 1),\n",
    "                                                   (\"v_x\", float, 1),\n",
    "                                                   (\"v_y\", float, 1)])\n",
    "\n",
    "        # Set initial source positions\n",
    "        self.sources[\"theta_x\"] = self.sources[\"theta_x_0\"]\n",
    "        self.sources[\"theta_y\"] = self.sources[\"theta_y_0\"]\n",
    "\n",
    "        # Set initial lens positions...\n",
    "        self.lenses[\"theta_x\"] = np.array(pos_l)[:, 0]\n",
    "        self.lenses[\"theta_y\"] = np.array(pos_l)[:, 1]\n",
    "\n",
    "        # ... and lens properties\n",
    "        self.lenses[\"v_x\"] = np.array(v_l)[:, 0]\n",
    "        self.lenses[\"v_y\"] = np.array(v_l)[:, 1]\n",
    "        self.lenses[\"M_0\"] = np.array(M_l)\n",
    "        self.lenses[\"R_0\"] = np.array(R_l)\n",
    "        self.lenses[\"D\"] = np.array(D_l)\n",
    "\n",
    "        theta_s = np.zeros((self.n_total, 2))\n",
    "\n",
    "        # Deflection and proper motion vectors\n",
    "        for i_lens in range(self.n_lens):\n",
    "            b_ary = np.transpose([self.sources[\"theta_x\"] - self.lenses[\"theta_x\"][i_lens],\n",
    "                                  self.sources[\"theta_y\"] - self.lenses[\"theta_y\"][i_lens]]) * asctorad\n",
    "\n",
    "            vel_l = np.array([self.lenses[\"v_x\"][i_lens],\n",
    "                              self.lenses[\"v_y\"][i_lens]])\n",
    "            \n",
    "            for i_source in range(self.n_total):\n",
    "\n",
    "                theta_s[i_source] += self.theta(b_ary[i_source], self.lenses[\"R_0\"][i_lens],\n",
    "                                                self.lenses[\"M_0\"][i_lens], self.lenses[\"D\"][i_lens])\n",
    "                        \n",
    "        # New source positions including deflection\n",
    "        self.sources[\"theta_x\"] = self.sources[\"theta_x_0\"] + theta_s[:, 0]\n",
    "        self.sources[\"theta_y\"] = self.sources[\"theta_y_0\"] + theta_s[:, 1]\n",
    "\n",
    "    def update(self, dt):\n",
    "        \"\"\" Update animation \"\"\"\n",
    "\n",
    "        theta_s = np.zeros((self.n_total, 2))\n",
    "\n",
    "        for i_lens in range(self.n_lens):\n",
    "            \n",
    "            b_ary = np.transpose([self.sources[\"theta_x\"] - self.lenses[\"theta_x\"][i_lens],\n",
    "                                  self.sources[\"theta_y\"] - self.lenses[\"theta_y\"][i_lens]]) * asctorad\n",
    "\n",
    "            vel_l = np.array([self.lenses[\"v_x\"][i_lens],\n",
    "                              self.lenses[\"v_y\"][i_lens]])\n",
    "            \n",
    "            for i_source in range(self.n_total):    \n",
    "                \n",
    "                theta_s[i_source] += self.theta(b_ary[i_source], self.lenses[\"R_0\"][i_lens],\n",
    "                                                self.lenses[\"M_0\"][i_lens], self.lenses[\"D\"][i_lens])\n",
    " \n",
    "            mu_l = (vel_l / self.lenses[\"D\"][i_lens]) / (Year ** -1) * radtoasc\n",
    "            \n",
    "            self.lenses[\"theta_x\"][i_lens] = self.lenses[\"theta_x\"][i_lens] + mu_l[0] * dt\n",
    "            self.lenses[\"theta_y\"][i_lens] = self.lenses[\"theta_y\"][i_lens] + mu_l[1] * dt\n",
    "                    \n",
    "        # Update intrinsic source position\n",
    "        self.sources[\"theta_x_0\"] += self.mu_s_intrinsic[:, 0] * dt\n",
    "        self.sources[\"theta_y_0\"] += self.mu_s_intrinsic[:, 1] * dt\n",
    "                \n",
    "        self.sources[\"theta_x\"] = self.sources[\"theta_x_0\"] + theta_s[:, 0] \n",
    "        self.sources[\"theta_y\"] = self.sources[\"theta_y_0\"] + theta_s[:, 1]\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def mu(self, beta_vec, v_ang_vec, R_0, M_0, d_lens):\n",
    "        \"\"\" Get lens-induced proper motion vector\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert angular to physical impact parameter\n",
    "        b_vec = d_lens * np.array(beta_vec)\n",
    "        # Convert angular to physical velocity\n",
    "        v_vec = d_lens * np.array(v_ang_vec)\n",
    "        b = np.linalg.norm(b_vec)  # Impact parameter\n",
    "        M, dMdb, _ = Profiles.MdMdb_Gauss(b, R_0, M_0)\n",
    "        b_unit_vec = b_vec / b  # Convert angular to physical impact parameter\n",
    "        b_dot_v = np.dot(b_unit_vec, v_vec)\n",
    "        factor = (dMdb / b * b_unit_vec * b_dot_v\n",
    "                  + M / b ** 2 * (v_vec - 2 * b_unit_vec * b_dot_v))\n",
    "\n",
    "        return -factor * 4 * GN / (asctorad / Year)  # Convert to as/yr\n",
    "\n",
    "    @classmethod\n",
    "    def theta(self, beta_vec, R_0, M_0, d_lens):\n",
    "        \"\"\" Get lens-induced deflection vector\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert angular to physical impact parameter\n",
    "        b_vec = d_lens * np.array(beta_vec)\n",
    "        b = np.linalg.norm(b_vec)  # Impact parameter\n",
    "        M, _, _ = Profiles.MdMdb_Gauss(b, R_0, M_0)\n",
    "        b_unit_vec = b_vec / b  # Convert angular to physical impact parameter\n",
    "\n",
    "        return 4 * GN * M / b * b_unit_vec * radtoasc  # Convert to as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258448/4169467666.py:48: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  self.sources = np.zeros(self.n_total, dtype=[(\"theta_x\", float, 1),\n",
      "/tmp/ipykernel_258448/4169467666.py:86: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  self.lenses = np.zeros(self.n_lens, dtype=[(\"theta_x\", float, 1),\n"
     ]
    }
   ],
   "source": [
    "ds = DemoSim(theta_x_lims = [-0.1, 0.1], theta_y_lims = [-0.1, 0.1])\n",
    "ds.animation(pos_l=np.array([[0.,0]]), v_l=np.array([[200, 0]]) * Kmps, R_l=[10 * pc], M_l=[0],\n",
    "                        D_l=[1 * kpc],\n",
    "                        n_dens=500,\n",
    "                        std_mu_s=1e-6,\n",
    "                        source_pos=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8912cbb426924054afe670da50d9294e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258448/4169467666.py:48: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  self.sources = np.zeros(self.n_total, dtype=[(\"theta_x\", float, 1),\n",
      "/tmp/ipykernel_258448/4169467666.py:86: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  self.lenses = np.zeros(self.n_lens, dtype=[(\"theta_x\", float, 1),\n"
     ]
    }
   ],
   "source": [
    "n_sim = 10000\n",
    "\n",
    "x = np.zeros((n_sim, ds.n_total, 10, 2))\n",
    "y = np.zeros((n_sim))\n",
    "\n",
    "for i_sim in tqdm(range(n_sim)):\n",
    "    \n",
    "    ds = DemoSim(theta_x_lims = [-0.1, 0.1], theta_y_lims = [-0.1, 0.1])\n",
    "    \n",
    "    y_lens = np.random.randint(2)\n",
    "    y[i_sim] = y_lens\n",
    "    \n",
    "    if y_lens:\n",
    "        M_l = 10 ** 7. * M_s\n",
    "    else:\n",
    "        M_l = 0\n",
    "    \n",
    "    pos_l = 0.1 * (np.random.random(2) - 0.5)\n",
    "    v_l = 300. * (np.random.random(2) - 0.5)\n",
    "    \n",
    "    anim = ds.animation(pos_l=np.array([pos_l]), v_l=np.array([v_l]) * Kmps, R_l=[1 * pc], M_l=[M_l],\n",
    "                        D_l=[1 * kpc],\n",
    "                        n_dens=500,\n",
    "                        std_mu_s=2e-5,\n",
    "                        source_pos=\"random\")\n",
    "\n",
    "    for i in range(10):\n",
    "        \n",
    "        ds.update(dt=10)\n",
    "        \n",
    "        x[i_sim, : , i, 0] = ds.sources[\"theta_x\"]\n",
    "        x[i_sim, : , i, 1] = ds.sources[\"theta_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_mu = 2e-5\n",
    "x_err = np.random.normal(loc=0, scale=error_mu, size=(x.shape))\n",
    "\n",
    "x += x_err\n",
    "x = torch.Tensor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-series deep set model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and rotate data\n",
    "x -= x[:, :, 0, :].unsqueeze(-2)\n",
    "theta = torch.atan(x[:, :, -1, 1] / x[:, :, -1, 0]).numpy()\n",
    "rot = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
    "torch.Tensor(rot)\n",
    "rot = torch.Tensor(rearrange(rot, 'i j k l  -> k l i j'))\n",
    "x = torch.matmul(x, rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSetLSTM(nn.Module):\n",
    "    def __init__(self, num_outputs=1, dim_output=1, dim_hidden=128):\n",
    "        super(DeepSetLSTM, self).__init__()\n",
    "        \n",
    "        self.num_outputs = num_outputs\n",
    "        self.dim_output = dim_output\n",
    "        self.dim_hidden = dim_hidden\n",
    "        \n",
    "        self.phi = nn.LSTM(input_size=2, hidden_size=dim_hidden, num_layers=8, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.rho = nn.Sequential(\n",
    "                nn.Linear(2 * dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, num_outputs*dim_output))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = rearrange(x, 'b s t xy -> (b s) t xy')\n",
    "        x, (h, c) = self.phi(x) \n",
    "        h = rearrange(h, '(d l) b h -> b d l h', d=2)[:, :, -1, :]\n",
    "        h = rearrange(h, 'b d h -> b (d h)')\n",
    "        \n",
    "        h = rearrange(h, '(b s) h -> b s h', b=batch_size).mean(-2)\n",
    "        \n",
    "        x = self.rho(h).reshape(-1, self.num_outputs, self.dim_output)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split, SubsetRandomSampler\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "x = (x - x.mean(0).mean(0)) / x.std(0).std(0)\n",
    "x[:, :, 0, :] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fraction = 0.1\n",
    "n_samples_val = int(val_fraction * len(x))\n",
    "\n",
    "dataset = TensorDataset(x, y)\n",
    "\n",
    "dataset_train, dataset_val = random_split(dataset, [len(x) - n_samples_val, n_samples_val])\n",
    "train_loader = DataLoader(dataset_train, batch_size=64, num_workers=8, pin_memory=True, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=64, num_workers=8, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBlipClassifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.deepset = DeepSetLSTM()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        optimizer = optim.AdamW(self.parameters(), lr=5e-3, weight_decay=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=4)\n",
    "        \n",
    "        return {\"optimizer\": optimizer, \n",
    "                    \"lr_scheduler\": {\n",
    "                    \"scheduler\": scheduler,\n",
    "                    \"interval\": \"epoch\",\n",
    "                    \"monitor\": \"val_loss\",\n",
    "                    \"frequency\": 1}\n",
    "                }\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.deepset(x)\n",
    "        loss = nn.BCEWithLogitsLoss(reduction='mean')(y_hat[:,0,0], y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.deepset(x)\n",
    "        loss = nn.BCEWithLogitsLoss(reduction='mean')(y_hat[:,0,0], y)\n",
    "        self.log('val_loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiBlipClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name    | Type        | Params\n",
      "----------------------------------------\n",
      "0 | deepset | DeepSetLSTM | 3.0 M \n",
      "----------------------------------------\n",
      "3.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 M     Total params\n",
      "12.070    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/n/home11/smsharma/.conda/envs/deepsets/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/n/home11/smsharma/.conda/envs/deepsets/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/n/home11/smsharma/.conda/envs/deepsets/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/n/home11/smsharma/.conda/envs/deepsets/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ccd0e59b7c4c2799b6a8c58eb43a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\")\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=8)        \n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=25, gpus=1, gradient_clip_val=1., callbacks=[checkpoint_callback, early_stop_callback, lr_monitor])\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "model.load_from_checkpoint(checkpoint_callback.best_model_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
